{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna import Generator, ModelWrapper, MultiGenerator\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna.sequence import SeqIntervalDl, StringSeqIntervalDl\n",
    "import os\n",
    "os.chdir('tutorial_dr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To experiment the possible usage of `keras_dna` in the context of regression, we will train a neural network to predict the nucleosome density in $\\textit{S.cerevisiae}$ directly from the DNA sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needed are :\n",
    "- the DNA sequence in a fasta file.\n",
    "- an experimental nucleosome coverage in bigwig format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: impossible de créer le répertoire « tutorial_dr »: File exists\n",
      "--2020-04-29 11:02:56--  http://hgdownload.soe.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.fa.gz\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 3820548 (3.6M) [application/x-gzip]\n",
      "Sauvegarde en : « sacCer3.fa.gz »\n",
      "\n",
      "sacCer3.fa.gz       100%[===================>]   3.64M  1.10MB/s    ds 4.7s    \n",
      "\n",
      "2020-04-29 11:03:01 (798 KB/s) — « sacCer3.fa.gz » sauvegardé [3820548/3820548]\n",
      "\n",
      "gzip: sacCer3.fa: unknown suffix -- ignored\n",
      "--2020-04-29 11:03:01--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0010101/Saccharomyces_cerevisiae.scNuc0010101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 2760717 (2.6M) [text/plain]\n",
      "Sauvegarde en : « Saccharomyces_cerevisiae.scNuc0010101.nucleosome.shift.bw »\n",
      "\n",
      "Saccharomyces_cerev 100%[===================>]   2.63M  1.84MB/s    ds 1.4s    \n",
      "\n",
      "2020-04-29 11:03:03 (1.84 MB/s) — « Saccharomyces_cerevisiae.scNuc0010101.nucleosome.shift.bw » sauvegardé [2760717/2760717]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir tutorial_dr\n",
    "os.chdir('tutorial_dr')\n",
    "\n",
    "!wget http://hgdownload.soe.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.fa.gz\n",
    "!gunzip sacCer3.fa\n",
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0010101/Saccharomyces_cerevisiae.scNuc0010101.nucleosome.shift.bw\n",
    "!mv Saccharomyces_cerevisiae.scNuc0010101.nucleosome.shift.bw scerevisiae.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a 1d CNN with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a 1d convolutionnal network with three convolutionnal layers. This model will be trained to predict the nucleosome density at the center of a 2001 bp DNA window. \n",
    "\n",
    "The models inputs are of shape (batch_size, 2001, 4). The outputs are of shape (batch_size, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(2001, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='linear'))\n",
    "          \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      min_delta=0,\n",
    "                                      patience=10,\n",
    "                                      verbose=0,\n",
    "                                      mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `Generator` class to feed the train set data to our model. One needs to pass the DNA sequence in a fasta file, the nucleosome density in bigwig. One needs to specify the batch size (here 64) and the length of input windows (2001 bp).\n",
    "\n",
    "In this example we restrict our train set to the 6 first chromosomes and the output_shape is specified to correspond to the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 1),\n",
    "                            rc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now associate the model to its specific train generator in a `ModelWrapper` instance. In this case we will also associate another `Generator` to our model : the validation generator. This generator is used in the validation process and yields data coming from chromosome 7 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = wrap.predict(incl_chromosomes=['chrIX'],\n",
    "                         chrom_size='sacCer3.chrom.sizes',\n",
    "                         rc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use the `train` method to train the model. One can also pass arguments that will be used by the keras model method [fit_generator](https://keras.io/models/sequential/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation can be made on a new chromosome with the method `evaluate`. Arguments can be passed to the keras model method [evaluate_generator](https://keras.io/models/sequential/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309/1309 [==============================] - 81s 62ms/step - loss: 47.6814 - mae: 1.1979\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'metric_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7dd6f3e905d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincl_chromosomes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chrM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/keras_dna/keras_dna/model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, incl_chromosomes, generator_eval, weights_eval, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m                                                     **kwargs)\n\u001b[1;32m    161\u001b[0m         return {metric : evaluation for metric, evaluation in\\\n\u001b[0;32m--> 162\u001b[0;31m                 zip(self.model.metric_names, evaluations)}\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     def get_auc(self,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'metric_names'"
     ]
    }
   ],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chrM'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specificaly calculate the correlation between the predicted and experimental nucleosome density. Use the method `get_correlation` to do so. It also use internally the evaluate_generator keras method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrM'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As nucleosome density is an experimental data, one needs to normalize it for comparison purpose. It is also a good practise to remove outliers before calculating any metrics. Here we will cut the distribution to the last percentile and divide by the resulant maximum.\n",
    "\n",
    "To do so we ude the keyword normalization_mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding weights to balance the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of score of nucleosome density is not flat, it means that rare score will tend to be ill predicted by the model because they account for virtualy nothing in the loss function. To compensate this fact an usual strategy is to add weights during the training for the loss calculation.\n",
    "\n",
    "To balance the relative importance of scores one can pass 'balanced' to the weighting_mode keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            weighting_mode='balanced',\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the keyword weights_val to specify that one wants to apply the weights to calculate metrics on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'],\n",
    "                    weights_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the evaluation process one can specify if one wants to include weights with the keyword weights_eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chrIX'], verbose=1, weights_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1, weights_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the `ModelWrapper` instance in a hdf5 file with the methos `save`.\n",
    "\n",
    "Be aware, as it is usual to save the best model obtained during the training process (with the keras callbacks [ModelCheckpoint](https://keras.io/callbacks/)), one may not want to overwrite the model at the end of training. To prevent the method from overwritting the model, set the keyword save_model to False (default behaviour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.save('./weights_CNN_nucleosome_normalized_weighted.hdf5',\n",
    "          save_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a `ModelWrapper` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna.model import load_wrapper, load_generator_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First situation, one wants to reuse a `ModelWrapper` instance and to reuse both the model and the data, furthermore the path to access the data is unchanged since saving time.  \n",
    "\n",
    "The method `load_wrapper` loads both the model and the generator with the original data, the path to access data must therefore be unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = load_wrapper('./weights_CNN_nucleosome_normalized_weighted.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with the loaded instance as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.get_correlation(incl_chromosomes=['chrIX'], verbose=1, weights_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second situtation, we want to reuse the model of a `ModelWrapper` but with new data (or just because their localisation has changed since saving). The module `load_generator_command` gives us access to a tuple of dictionaries that can be used to recreate the training and validation generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exemple we will reuse our saved model and calculate the correlation of its prediction with a new experimental nucleosome density.\n",
    "\n",
    "First, we need to downlaod the new data. Then, we can download the dictionaries to see how to create train and validation generators adapted to the model and then load the model with the keras method `load_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-01 11:32:30--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0020101/Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 2525167 (2.4M) [text/plain]\n",
      "Sauvegarde en : « Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw »\n",
      "\n",
      "Saccharomyces_cerev 100%[===================>]   2.41M  1.85MB/s    ds 1.3s    \n",
      "\n",
      "2020-05-01 11:32:32 (1.85 MB/s) — « Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw » sauvegardé [2525167/2525167]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0020101/Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw\n",
    "!mv Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw scerevisiae2.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Generator',\n",
       " 'arguments': {'batch_size': 64,\n",
       "  'one_hot_encoding': True,\n",
       "  'output_shape': [64, 1],\n",
       "  'weighting_mode': 'balanced',\n",
       "  'bins': 'auto',\n",
       "  'fasta_file': 'sacCer3.fa',\n",
       "  'annotation_files': ['scerevisiae.bw'],\n",
       "  'window': 2001,\n",
       "  'normalization_mode': ['max', 'perctrim'],\n",
       "  'incl_chromosomes': ['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI']}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_train, command_val = load_generator_command('./weights_CNN_nucleosome_normalized_weighted.hdf5')\n",
    "command_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./weights_CNN_nucleosome_normalized_weighted.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the name of the bigwig file in the dictionnary to evaluate the same model on a new data. (can especially be useful for transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'one_hot_encoding': True,\n",
       " 'output_shape': [64, 1],\n",
       " 'weighting_mode': 'balanced',\n",
       " 'bins': 'auto',\n",
       " 'fasta_file': 'sacCer3.fa',\n",
       " 'annotation_files': ['scerevisiae2.bw'],\n",
       " 'window': 2001,\n",
       " 'normalization_mode': ['max', 'perctrim'],\n",
       " 'incl_chromosomes': ['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_train = command_train['arguments']\n",
    "command_val = command_val['arguments']\n",
    "\n",
    "command_train['annotation_files'] = ['scerevisiae2.bw']\n",
    "command_val['annotation_files'] = ['scerevisiae2.bw']\n",
    "command_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(**command_train)\n",
    "generator_val = Generator(**command_val)\n",
    "\n",
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    generator_val=generator_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the module `get_correlation` owns keywords to do cross-prediction without the need of recreating totally new generators by hand (not `evaluate`)\n",
    "\n",
    "For example, say we want to evaluate if our model trained on S.cerevisiae is able to predict the nucleosome density on C.elegans. We will download the C.elegans genome as well as an experimental nucleosome density and calculate the correlation between the predicted density and the experimental one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-01 14:39:24--  https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.fa.gz\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 31816111 (30M) [application/x-gzip]\n",
      "Sauvegarde en : « ce11.fa.gz »\n",
      "\n",
      "ce11.fa.gz          100%[===================>]  30.34M  8.44MB/s    ds 6.8s    \n",
      "\n",
      "2020-05-01 14:39:32 (4.47 MB/s) — « ce11.fa.gz » sauvegardé [31816111/31816111]\n",
      "\n",
      "gzip: cell.fa.gz: No such file or directory\n",
      "--2020-05-01 14:39:32--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Caenorhabditis_elegans/bySample/ceNuc0010101/Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 19735260 (19M) [text/plain]\n",
      "Sauvegarde en : « Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw »\n",
      "\n",
      "Caenorhabditis_eleg 100%[===================>]  18.82M  1.73MB/s    ds 13s     \n",
      "\n",
      "2020-05-01 14:39:46 (1.41 MB/s) — « Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw » sauvegardé [19735260/19735260]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.fa.gz\n",
    "!gunzip ce11.fa.gz\n",
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Caenorhabditis_elegans/bySample/ceNuc0010101/Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw\n",
    "!mv Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw celegans.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One needs to pass the fasta file as well as the bigwig file to the `get_correlation` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 13s 72ms/step - loss: 66987.2414 - metric: 0.0211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': 0.021094829}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrM'],\n",
    "                     fasta_file='ce11.fa',\n",
    "                     annotation_files=['celegans.bw'],\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on a full chromosomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the method `predict` to predict the nucleosome density on full chromosomes, this prediction can be exported to a bigwig file (if a path is passed as argument). One needs to pass a file with chromosome size in two columns tab separated to the method, its name should end with .chrom.sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-01 11:46:06--  https://hgdownload.soe.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.chrom.sizes\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 229 [text/plain]\n",
      "Sauvegarde en : « sacCer3.chrom.sizes »\n",
      "\n",
      "sacCer3.chrom.sizes 100%[===================>]     229  --.-KB/s    ds 0s      \n",
      "\n",
      "2020-05-01 11:46:07 (3.46 MB/s) — « sacCer3.chrom.sizes » sauvegardé [229/229]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.chrom.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36926/36926 [==============================] - 1010s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrIX', 'chrX'],\n",
    "                          chrom_size='sacCer3.chrom.sizes',\n",
    "                          export_to_path='prediction_chrIX_chrX.bw',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict on a different genome for example C.elegans with the model trained on S.cerevisiae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-01 14:42:28--  https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.chrom.sizes\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 99 [text/plain]\n",
      "Sauvegarde en : « ce11.chrom.sizes »\n",
      "\n",
      "ce11.chrom.sizes    100%[===================>]      99  --.-KB/s    ds 0s      \n",
      "\n",
      "2020-05-01 14:42:29 (3.42 MB/s) — « ce11.chrom.sizes » sauvegardé [99/99]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.chrom.sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict and export the prediction in a cross-species context. One just needs to pass the genome of the new species in a fasta file as well as the adapted chromosome sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 10s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrM'],\n",
    "                          chrom_size='ce11.chrom.sizes',\n",
    "                          fasta_file='ce11.fa',\n",
    "                          export_to_path='prediction_celegans.bw',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can predict the nucleosome density with the reversed complemented DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrM'], chrom_size='sacCer3.chrom.sizes', rc=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with multiple inputs / outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with another tracks as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this functionnality we will train a model that takes DNA windows of 2001 bp as inputs as well as the nucleosome density of the 100 centers nucleotides coming from one experiment and predict the the same nucleosome density for another experiment. It is somehow an experiment translators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a multi input model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_extractor = keras.models.Sequential()\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(2001, 4)))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Flatten())\n",
    "\n",
    "dna_inputs = keras.layers.Input(shape=(2001, 4))\n",
    "seq_inputs = keras.layers.Input(shape=(100,))\n",
    "\n",
    "dna_features = dna_extractor(dna_inputs)\n",
    "concatenate = keras.layers.Concatenate()([dna_features, seq_inputs])\n",
    "outputs = keras.layers.Dense(100)(concatenate)\n",
    "\n",
    "model = keras.models.Model([dna_inputs, seq_inputs], outputs)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the corresponding `Generator` instance in order to feed the model with training data. Note that we use a serie of keyword begining by seq to control the secondary input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            tg_window=100,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 100),\n",
    "                            sec_inputs=['scerevisiae2.bw'],\n",
    "                            sec_input_length=100,\n",
    "                            sec_input_shape=(64, 100),\n",
    "                            sec_normalization_mode=['max', 'perctrim'],\n",
    "                            use_sec_as='inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is now transparent, we can create a `ModelWrapper` instance, train and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.0085 - val_loss: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feca470cf98>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=5,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 6s 89ms/step - loss: 0.0099 - metric: 0.9362 1s - los\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': 0.9361512}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting two tracks at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw previously, the nucleosome density can change from one experiment to another. We may want to predict several experimental densities at the same time. \n",
    "\n",
    "Here we create a model to predict the nucleosome density at the 100 center nucleotides of every 2001 bp DNA window. We will also predict two experimental densities at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_track1 = keras.layers.Dense(100)(dna_features)\n",
    "output_track1 = keras.layers.Reshape((100, 1))(output_track1)\n",
    "\n",
    "output_track2 = keras.layers.Dense(100)(dna_features)\n",
    "output_track2 = keras.layers.Reshape((100, 1))(output_track2)\n",
    "\n",
    "output = keras.layers.Concatenate(axis=2, name='output')([output_track1, output_track2])\n",
    "model = keras.models.Model(dna_inputs, output)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference is that now we pass two bigwig files to the keyword annotation_files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw', 'scerevisiae2.bw'],\n",
    "                            window=2001,\n",
    "                            tg_window=100,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0458 - val_loss: 0.0344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13e8416828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=1,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_correlation` will display the correlation between every predicted density and its corresponding experimental one. As a contrary `evaluate` calculate the mean evaluation on all tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 7s 100ms/step - loss: 0.1910 - correlate_0_0: 0.0031 - correlate_1_0: 2.8998e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': 0.003099391, 'correlate_1_0': 0.00028997537}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `predict` will in this case export one bigwig file for every prediction made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 5s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrIX'],\n",
    "                          export_to_path='prediction_multi_training.bw',\n",
    "                          chrom_size='sacCer3.chrom.sizes',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on several species simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras_dna` makes it easy to use model in a cross species context. To go a step further we want to predict the nucleosome density on both $\\textit{S.cerevisiae}$ and $\\textit{C.elegans}$ at the same time.\n",
    "\n",
    "To do so we will use two new classes `SeqIntervalDl` and `MultiGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna import SeqIntervalDl, MultiGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes a DNA window of 2001 bp as input and predict the nucleosome density on the 100 centers nucleotides of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(2001, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='linear'))\n",
    "          \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the `MultiGenerator` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of creating a `MultiGeneraor` is not as straighforward as for a `Generator`.\n",
    "\n",
    "One needs first to create a dataset (`SeqIntervalDl` instance) for every species, the keyword are the same as with a `Generator` except batch_size and output_shape that will be passed to the `MultiGenerator`.\n",
    "\n",
    "The `MultiGenerator` is created by passing it the list of dataset. In our example we also pass the number of exemples that we want our generator to yield from every species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_saccer = SeqIntervalDl(fasta_file='sacCer3.fa',\n",
    "                               annotation_files='scerevisiae.bw',\n",
    "                               normalization_mode=['max', 'perctrim'],\n",
    "                               window=2001,\n",
    "                               tg_window=100,\n",
    "                               rc=True,\n",
    "                               incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'])\n",
    "\n",
    "dataset_celegand = SeqIntervalDl(fasta_file='ce11.fa',\n",
    "                                 annotation_files='celegans.bw',\n",
    "                                 normalization_mode=['max', 'perctrim'],\n",
    "                                 window=2001,\n",
    "                                 tg_window=100,\n",
    "                                 incl_chromosomes=['chrI', 'chrII'])\n",
    "\n",
    "generator_train = MultiGenerator(batch_size=64,\n",
    "                                 dataset_list=[dataset_saccer, dataset_celegand],\n",
    "                                 inst_per_dataset=[64*500, 64*500],\n",
    "                                 output_shape=(64, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same procedure apply for the cretion of the validation generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_saccer_val = SeqIntervalDl(fasta_file='sacCer3.fa',\n",
    "                                   annotation_files='scerevisiae.bw',\n",
    "                                   normalization_mode=['max', 'perctrim'],\n",
    "                                   window=2001,\n",
    "                                   tg_window=100,\n",
    "                                   incl_chromosomes=['chrVII', 'chrVIII'])\n",
    "\n",
    "dataset_celegand_val = SeqIntervalDl(fasta_file='ce11.fa',\n",
    "                                     annotation_files='celegans.bw',\n",
    "                                     normalization_mode=['max', 'perctrim'],\n",
    "                                     window=2001,\n",
    "                                     tg_window=100,\n",
    "                                     incl_chromosomes=['chrIII'])\n",
    "\n",
    "generator_val = MultiGenerator(batch_size=64,\n",
    "                               dataset_list=[dataset_saccer_val, dataset_celegand_val],\n",
    "                               inst_per_dataset=[64*200, 64*200],\n",
    "                               output_shape=(64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    generator_val=generator_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally if we want to evaluate our generator we need to specify the species.\n",
    "\n",
    "The method `evaluate` requires to create a new generator to yield the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_test = Generator(batch_size=64,\n",
    "                           fasta_file='sacCer3.fa',\n",
    "                           annotation_files='scerevisiae.bw',\n",
    "                           normalization_mode=['max', 'perctrim'],\n",
    "                           window=2001,\n",
    "                           tg_window=100,\n",
    "                           incl_chromosomes=['chrM'],\n",
    "                           output_shape=(64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(generator_eval=generator_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `get_correlation` requires to pass the genome we want to predict on and the nucleosome density we want to compare with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 9s 75ms/step - loss: 0.1759 - metric: -0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': -0.0020717818}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrX'],\n",
    "                     fasta_file='sacCer3.fa',\n",
    "                     annotation_files=['scerevisiae.bw'],\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `predict` requires to pass the genome we want to predict on as well as the corresponding chromosome sizes file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 7s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01883128, -0.04754147, -0.0131825 , ...,  0.13192448,\n",
       "        -0.04590571, -0.0558481 ],\n",
       "       [-0.02511727,  0.1061755 , -0.02488164, ...,  0.10167224,\n",
       "         0.0442229 , -0.15225634],\n",
       "       [-0.09656224, -0.05785175,  0.01321044, ...,  0.13336149,\n",
       "         0.09787058, -0.0496234 ],\n",
       "       ...,\n",
       "       [-0.12513319,  0.13154107, -0.11106987, ...,  0.09564744,\n",
       "         0.03229365, -0.08686507],\n",
       "       [-0.05958488,  0.01612343, -0.07622039, ...,  0.18101265,\n",
       "        -0.0049902 , -0.08667748],\n",
       "       [-0.07636375,  0.03420825, -0.01399545, ...,  0.129873  ,\n",
       "         0.05479156, -0.03051661]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.predict(incl_chromosomes=['chrX'],\n",
    "             chrom_size='sacCer3.chrom.sizes',\n",
    "             fasta_file='sacCer3.fa',\n",
    "             export_to_path='multi_prediction.bw',\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will classify DNA sequence between being a binding site for a transcription factor from being background. We will use binding site of a proteins called TAF15 in human genome. The sites as defined as peaks of Chip-Seq.\n",
    "\n",
    "First, we will download the data, then create a convolutional classifier and finally create a `Generator` instance adapted to our model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-07 10:45:03--  https://ftp.ncbi.nlm.nih.gov/geo/series/GSE105nnn/GSE105202/suppl/GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz\n",
      "Résolution de ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)… 130.14.250.7, 2607:f220:41e:250::10\n",
      "Connexion à ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.7|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 6235743 (5.9M) [application/x-gzip]\n",
      "Sauvegarde en : « GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz »\n",
      "\n",
      "GSE105202_ENCFF979T 100%[===================>]   5.95M  6.76MB/s    ds 0.9s    \n",
      "\n",
      "2020-05-07 10:45:05 (6.76 MB/s) — « GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz » sauvegardé [6235743/6235743]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
    "!gunzip hg38.fa.gz\n",
    "\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE105nnn/GSE105202/suppl/GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz\n",
    "!gunzip GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz\n",
    "!mv GSE105202_ENCFF979TPQ_peaks_GRCh38.bed taf15.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study the bed file to see what is the number of available positive annotatio and the typical length of a Chip-Seq peak. We are also interested in the distribution of peaks in chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2</td>\n",
       "      <td>195656836</td>\n",
       "      <td>195657387</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>366.644608</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2</td>\n",
       "      <td>148645132</td>\n",
       "      <td>148645562</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>323.084459</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr7</td>\n",
       "      <td>35800963</td>\n",
       "      <td>35801305</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>289.978500</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr10</td>\n",
       "      <td>95656633</td>\n",
       "      <td>95656950</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>269.324547</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr7</td>\n",
       "      <td>26200724</td>\n",
       "      <td>26201117</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>258.250077</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom      start       stop  0  1  2           3  4         5    6\n",
       "0   chr2  195656836  195657387  .  0  .  366.644608 -1  3.198382  312\n",
       "1   chr2  148645132  148645562  .  0  .  323.084459 -1  3.198382  260\n",
       "2   chr7   35800963   35801305  .  0  .  289.978500 -1  3.198382  185\n",
       "3  chr10   95656633   95656950  .  0  .  269.324547 -1  3.198382  158\n",
       "4   chr7   26200724   26201117  .  0  .  258.250077 -1  3.198382  148"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bedfile = pd.read_csv('taf15.bed', sep='\\t', names=['chrom', 'start', 'stop', '0', '1', '2', '3', '4', '5', '6'])\n",
    "bedfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bedfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551, 120, 404.0, 2.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedfile['length'] = bedfile.stop.values - bedfile.start.values\n",
    "bedfile.length.max(), bedfile.length.min(), round(bedfile.length.mean()), round(bedfile.length.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390.0, 410.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = bedfile.length.hist(bins=100)\n",
    "ax.set_xlim(390, 410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299961"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bedfile[bedfile.length == 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of peaks on chromosome 1: 33264\n",
      "number of peaks on chromosome 2: 23056\n",
      "number of peaks on chromosome 3: 16904\n",
      "number of peaks on chromosome 4: 16387\n",
      "number of peaks on chromosome 5: 18490\n",
      "number of peaks on chromosome 6: 21000\n",
      "number of peaks on chromosome 7: 22871\n",
      "number of peaks on chromosome 8: 13834\n",
      "number of peaks on chromosome 9: 10067\n",
      "number of peaks on chromosome 10: 13201\n",
      "number of peaks on chromosome 11: 15203\n",
      "number of peaks on chromosome 12: 12347\n",
      "number of peaks on chromosome 13: 4693\n",
      "number of peaks on chromosome 14: 5367\n",
      "number of peaks on chromosome 15: 8144\n",
      "number of peaks on chromosome 16: 11585\n",
      "number of peaks on chromosome 17: 11829\n",
      "number of peaks on chromosome 18: 6147\n",
      "number of peaks on chromosome 19: 12005\n",
      "number of peaks on chromosome 20: 6855\n",
      "number of peaks on chromosome 21: 5179\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 22):\n",
    "    print('number of peaks on chromosome {}: {}'.format(i, len(bedfile[bedfile.chrom == 'chr' + str(i)])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a 1D convolutional classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes one-hot-encoded DNA window of 551 bp long as input and classify them between being a binding site or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(551, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the generator to train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fed with a `Generator` instance. The DNA sequence is passed through the fasta file, the positions of binding site are passed through the bed file, we need to precise the batch size and finally that we are predicting binding site.\n",
    "\n",
    "In this exemple we will train the network on the first five chromosomes, we need to precise the output shape as it is not standard, that the length of input DNA window is the maximal length and we will let the negative ratio to its default value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq_len=551,\n",
    "                            negative_ratio=1,\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                   generator_train=generator_train,\n",
    "                   validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3378/3378 [==============================] - 269s 80ms/step - loss: 0.6012 - accuracy: 0.6534 - val_loss: 0.5931 - val_accuracy: 0.6657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f55b4612160>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 20s 47ms/step - loss: 0.5892 - accuracy: 0.6690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5891944118258026, 0.6689815]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chr8'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One functionnality is to calculate the AUROC on all a chromosome. It gives an evaluation for a binding site detector at a chromosome scale. We can choose to either consider one positive example per binding site or to apply data augmentation. Negative examples areall the windows not having any intersection with positive examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_auc(incl_chromosomes=['chr8'], data_augmentation=False, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this evaluation can be made on another species if we pass the DNA sequence through a fasta file, and the annotation file. As an example we use the human genome as if it was a new species. We will calculate the area under Precision-Recall curve in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 25s 57ms/step - loss: 0.6990 - auc_3: 0.4918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cell_idx': 0, 'annotation': 'binding site', 'AUPR': 0.49177095}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_auc(incl_chromosomes=['chr8'],\n",
    "             fasta_file='hg38.fa',\n",
    "             data_augmentation=False,\n",
    "             annotation_files=['taf15.bed'],\n",
    "             curve='PR',\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our detector of bindning site in hand we can predict on all a chromosome the presence of binding site. To do so we use the method `predict`. As we saw before we need to pass the chromosome size as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-08 11:12:22--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 11672 (11K) [text/plain]\n",
      "Sauvegarde en : « hg38.chrom.sizes »\n",
      "\n",
      "hg38.chrom.sizes    100%[===================>]  11.40K  --.-KB/s    ds 0s      \n",
      "\n",
      "2020-05-08 11:12:23 (117 MB/s) — « hg38.chrom.sizes » sauvegardé [11672/11672]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 3s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chr8'],\n",
    "                          chrom_size='hg38.chrom.sizes',\n",
    "                          export_to_path='taf15_prediction.bw',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train our model with random sequence as negative exemple, it may be useful as a first easy training before reusing the network to train it with the real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq_len=551,\n",
    "                            negative_ratio=1,\n",
    "                            negative_type='random',\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                   generator_train=generator_train,\n",
    "                   validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3378/3378 [==============================] - 280s 83ms/step - loss: 0.0268 - accuracy: 0.9888 - val_loss: 0.0036 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56c8b4be80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background sequences are far more numerous than binding site. To mitigate this fact one can apply a data-augmentation procedure. All the sequences of length 414 bp containing a binding site are then considered as positive exemples (it multiplies roughly the number of positives examples by 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(414, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq_len=414,\n",
    "                            negative_ratio=1,\n",
    "                            data_augmentation=True,\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chr8'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to set precisely the position of binding site within sequences that contain one. To do so we will train a seq2seq model and limit the training data to positive examples. We will apply a data augmentation strategy to gain more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(16, (3, 1), activation='relu', padding='same', input_shape=(416, 4, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 1), padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (10, 1), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 1), padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (20, 1), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 1), padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2DTranspose(64, (20, 1), strides=(2, 1), activation='relu', padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2DTranspose(32, (10, 1), strides=(2, 1), activation='relu', padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2DTranspose(16, (3, 1), strides=(2, 1), activation='relu', padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(1, (1, 4), activation='sigmoid', padding='valid'))\n",
    "model.add(keras.layers.Reshape((416, 1)))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq2seq=True,\n",
    "                            data_augmentation=True,\n",
    "                            defined_positive='match_any',\n",
    "                            seq_len=416,\n",
    "                            dummy_axis=2,\n",
    "                            negative_type=None,\n",
    "                            output_shape=(64, 416, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chr8'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Genome training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our network we use the hg38 genome in the direct strand. As an exemple of training a network on several genome at the same tile we will use hg38in the direct strand and hg38 in the reverse strand.\n",
    "\n",
    "Note that the procedure is the same if we want to train a network on several genome at the same time (several species, assembly). In particular we use `SeqIntervalDl` and `MultiGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna import SeqIntervalDl, MultiGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(551, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare one `SeqIntervalDl` instance in the direct strand and another in the reverse one. They are associated in a `MultiGenerator` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_direct = SeqIntervalDl(fasta_file='hg38.fa',\n",
    "                                annotation_files=['taf15.bed'],\n",
    "                                annotation_list=['binding site'],\n",
    "                                incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                                seq_len=551,\n",
    "                                negative_ratio=1,\n",
    "                                negative_type='real')\n",
    "\n",
    "dataset_reversed = SeqIntervalDl(fasta_file='hg38.fa',\n",
    "                                  annotation_files=['taf15.bed'],\n",
    "                                  annotation_list=['binding site'],\n",
    "                                  incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                                  seq_len=551,\n",
    "                                  negative_ratio=1,\n",
    "                                  rc=True,\n",
    "                                  negative_type='real')\n",
    "\n",
    "generator_train = MultiGenerator(batch_size=64,\n",
    "                                 dataset_list=[dataset_direct, dataset_reversed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train)\n",
    "\n",
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the fasta file use for prediction needs to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_auc(incl_chromosomes=['chr8'],\n",
    "             data_augmentation=True,\n",
    "             fasta_file='hg38.fa',\n",
    "             annotation_files=['taf15.bed'],\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.predict(incl_chromosomes=['chr8'],\n",
    "             chrom_size='hg38.chrom.sizes',\n",
    "             fasta_file='hg38.fa',\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['test.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1'],\n",
    "                            seq_len=12,\n",
    "                            negative_ratio=1,\n",
    "                            negative_type=None,\n",
    "                            output_shape=(64, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_env]",
   "language": "python",
   "name": "conda-env-test_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
