{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pyBigWig with conda to take the libcurl dependencies into account\n",
    "! conda install pybigwig -c conda-forge -c bioconda\n",
    "! pip install keras_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna import Generator, ModelWrapper, MultiGenerator\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna.sequence import SeqIntervalDl, StringSeqIntervalDl\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To experiment the possible usage of `keras_dna` in the context of regression, we will train a neural network to predict the nucleosome density in $\\textit{S.cerevisiae}$ directly from the DNA sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needed are :\n",
    "- the DNA sequence in a fasta file.\n",
    "- an experimental nucleosome coverage in bigwig format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir tutorial_dr\n",
    "os.chdir('tutorial_dr')\n",
    "\n",
    "!wget http://hgdownload.soe.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.fa.gz\n",
    "!gunzip sacCer3.fa\n",
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0010101/Saccharomyces_cerevisiae.scNuc0010101.nucleosome.shift.bw\n",
    "!mv Saccharomyces_cerevisiae.scNuc0010101.nucleosome.shift.bw scerevisiae.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a 1d CNN with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a 1d convolutionnal network with three convolutionnal layers. The model will be trained to predict the nucleosome density at the center of a 2001 bp DNA window. \n",
    "The model input shape is (batch_size, 2001, 4). The outputs are of shape (batch_size, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna import Generator, ModelWrapper, MultiGenerator\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(2001, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='linear'))\n",
    "          \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      min_delta=0,\n",
    "                                      patience=10,\n",
    "                                      verbose=0,\n",
    "                                      mode='auto')\n",
    "\n",
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 1))\n",
    "\n",
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])\n",
    "\n",
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(2001, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='linear'))\n",
    "          \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      min_delta=0,\n",
    "                                      patience=10,\n",
    "                                      verbose=0,\n",
    "                                      mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `Generator` class to feed our model with the training data. One needs to pass the DNA sequence in a fasta file, the nucleosome density in bigwig. One needs to specify the batch size (here 64) and the length of the input required by the network (2001 bp).\n",
    "\n",
    "In this example we restrict our train set to the 6 first chromosomes and the output_shape is specified to correspond to the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./tutorial_dr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now associate the model to its specific train generator in a `ModelWrapper` instance. In this case we will also associate another `Generator` to our model : the validation generator. This generator is used in the validation process and yields data coming from chromosome 7 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train` method to train the model. One can also pass arguments that will be used by the keras model method [fit_generator](https://keras.io/models/sequential/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation can be made on a new chromosome with the method `evaluate`. Arguments corresponding to the keras model method [evaluate_generator](https://keras.io/models/sequential/) can be passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309/1309 [==============================] - 83s 64ms/step - loss: 47.2756 - mae: 1.2058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[47.275604481257446, 1.2057654]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chrM'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specificaly calculate the correlation between the predicted and experimental nucleosome density. Use the method `get_correlation` to do so. It also use internally the evaluate_generator keras method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrM'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As nucleosome density is an experimental data, one needs to normalize it for comparison purpose. It is also a good practise to remove outliers before calculating any metrics. Here we will cut the distribution to the last percentile and divide by the new maximum.\n",
    "\n",
    "To do so we use the keyword normalization_mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available normalization are: \n",
    "\n",
    "- max : dividing by the maximum\n",
    "- perctrim: trimming the distribution to the last percentile\n",
    "- zscore\n",
    "- min_max \n",
    "\n",
    "Two consecutive normalizations can be applied, in the example perctrim is applied before max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding weights to balance the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the nucleosome density is not flat, it means that rare score will tend to be ill predicted by the model because they account for virtually nothing in the loss function. To compensate this fact an usual strategy is to add weights during the training for the loss calculation.\n",
    "\n",
    "To balance the relative importance of scores one can pass 'balanced' to the weighting_mode keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            weighting_mode='balanced',\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the keyword weights_val to specify that one wants to apply the weights to calculate metrics on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'],\n",
    "                    weights_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the evaluation process one can specify if one wants to include weights with the keyword weights_eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chrIX'], verbose=1, weights_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1, weights_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to create a `Generator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we saw how to build a `Generator` instance that generates data with a shape adapted to the model at hand. We present here some class method that enable to test the shape of the data generated before creating the `Generator` instance. We can play with the keywords to adapt the shape to our needs, note that the shape is returned without the batch_size axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the input shape with the class method `predict_input_shape`. The keyword dummy_axis and alphabet_axis enable to adapt the shape of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 1, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator.predict_input_shape(batch_size=64,\n",
    "                              fasta_file='sacCer3.fa',\n",
    "                              annotation_files=['scerevisiae.bw'],\n",
    "                              window=2001,\n",
    "                              dummy_axis=1,\n",
    "                              alphabet_axis=2,\n",
    "                              incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                              output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at the label shape by using the class method `predict_label_shape`. The useful keyword to change the label shape are:\n",
    "\n",
    "- the number of file passed through annotation_files\n",
    "- nb_annotation_type\n",
    "- tg_window\n",
    "- output_shape\n",
    "\n",
    "The tutorial will present how to use those keywords but you can play here to get an insight of how the label shape is organised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator.predict_label_shape(batch_size=64,\n",
    "                              fasta_file='sacCer3.fa',\n",
    "                              annotation_files=['scerevisiae.bw', 'scerevisiae.bw', 'scerevisiae.bw', 'scerevisiae.bw'],\n",
    "                              window=2001,\n",
    "                              tg_window=10,\n",
    "                              nb_annotation_type=2,\n",
    "                              output_shape=None,\n",
    "                              incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ModelWrapper` instance can be saved in a hdf5 file with the method `save`.\n",
    "\n",
    "Be aware, as it is usual to save the best model obtained during the training process (with the keras callbacks [ModelCheckpoint](https://keras.io/callbacks/)), one may  want not to overwrite the model at the end of training.\n",
    "To prevent the method from overwritting the model, set the keyword save_model to False (default behaviour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.save('./weights_CNN_nucleosome_normalized_weighted.hdf5',\n",
    "          save_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a `ModelWrapper` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna.model import load_wrapper, load_generator_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First situation, one wants to reuse a `ModelWrapper` instance and to reuse both the model and the data, furthermore the path to access the data is unchanged since saving time.  \n",
    "\n",
    "The method `load_wrapper` loads both the model and the generator with the original data, the path to access data must therefore be unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = load_wrapper('./weights_CNN_nucleosome_normalized_weighted.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with the loaded instance as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.get_correlation(incl_chromosomes=['chrIX'], verbose=1, weights_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second situtation, we want to reuse the model contained in a saved `ModelWrapper` instance but with new data (or just because their localisation has changed since saving). The module `load_generator_command`returns a tuple of dictionaries that can be used to recreate the training and validation generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exemple we will reuse our saved model and train it on a new experimental nucleosome density (transfer learning).\n",
    "\n",
    "First, we downlaod the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-23 10:00:50--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0020101/Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 2525167 (2.4M) [text/plain]\n",
      "Sauvegarde en : « Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw »\n",
      "\n",
      "Saccharomyces_cerev 100%[===================>]   2.41M   895KB/s    ds 2.8s    \n",
      "\n",
      "2020-07-23 10:00:53 (895 KB/s) — « Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw » sauvegardé [2525167/2525167]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0020101/Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw\n",
    "!mv Saccharomyces_cerevisiae.scNuc0020101.nucleosome.shift.bw scerevisiae2.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the dictionaries to see how to create train and validation generators adapted to the model with the method `load_generator_command`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Generator',\n",
       " 'arguments': {'batch_size': 64,\n",
       "  'one_hot_encoding': True,\n",
       "  'output_shape': [64, 1],\n",
       "  'weighting_mode': 'balanced',\n",
       "  'bins': 'auto',\n",
       "  'fasta_file': 'sacCer3.fa',\n",
       "  'annotation_files': ['scerevisiae.bw'],\n",
       "  'window': 2001,\n",
       "  'normalization_mode': ['max', 'perctrim'],\n",
       "  'incl_chromosomes': ['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI']}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_train, command_val = load_generator_command('./weights_CNN_nucleosome_normalized_weighted.hdf5')\n",
    "command_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load the model with the keras method `load_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./weights_CNN_nucleosome_normalized_weighted.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the name of the bigwig file in the dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'one_hot_encoding': True,\n",
       " 'output_shape': [64, 1],\n",
       " 'weighting_mode': 'balanced',\n",
       " 'bins': 'auto',\n",
       " 'fasta_file': 'sacCer3.fa',\n",
       " 'annotation_files': ['scerevisiae2.bw'],\n",
       " 'window': 2001,\n",
       " 'normalization_mode': ['max', 'perctrim'],\n",
       " 'incl_chromosomes': ['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_train = command_train['arguments']\n",
    "command_val = command_val['arguments']\n",
    "\n",
    "command_train['annotation_files'] = ['scerevisiae2.bw']\n",
    "command_val['annotation_files'] = ['scerevisiae2.bw']\n",
    "command_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new `Generator` instances that will match the model needs but with new data. We can then create a `ModelWrapper` instance to associate the model to its new training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(**command_train)\n",
    "generator_val = Generator(**command_val)\n",
    "\n",
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    generator_val=generator_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can train the model on new data (transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=100,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200,\n",
    "           callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate a model on new data the module `get_correlation` owns keywords to do so without the need of recreating totally new generators by hand (not `evaluate`).\n",
    "\n",
    "For example, say we want to evaluate if our model trained on S.cerevisiae is able to predict the nucleosome density on C.elegans. We will download the C.elegans genome as well as an experimental nucleosome density and calculate the correlation between the predicted density and the experimental one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-01 14:39:24--  https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.fa.gz\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 31816111 (30M) [application/x-gzip]\n",
      "Sauvegarde en : « ce11.fa.gz »\n",
      "\n",
      "ce11.fa.gz          100%[===================>]  30.34M  8.44MB/s    ds 6.8s    \n",
      "\n",
      "2020-05-01 14:39:32 (4.47 MB/s) — « ce11.fa.gz » sauvegardé [31816111/31816111]\n",
      "\n",
      "gzip: cell.fa.gz: No such file or directory\n",
      "--2020-05-01 14:39:32--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Caenorhabditis_elegans/bySample/ceNuc0010101/Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 19735260 (19M) [text/plain]\n",
      "Sauvegarde en : « Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw »\n",
      "\n",
      "Caenorhabditis_eleg 100%[===================>]  18.82M  1.73MB/s    ds 13s     \n",
      "\n",
      "2020-05-01 14:39:46 (1.41 MB/s) — « Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw » sauvegardé [19735260/19735260]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.fa.gz\n",
    "!gunzip ce11.fa.gz\n",
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Caenorhabditis_elegans/bySample/ceNuc0010101/Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw\n",
    "!mv Caenorhabditis_elegans.ceNuc0010101.nucleosome.shift.bw celegans.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One needs to pass the fasta file as well as the bigwig file to the `get_correlation` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 13s 72ms/step - loss: 66987.2414 - metric: 0.0211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': 0.021094829}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrM'],\n",
    "                     fasta_file='ce11.fa',\n",
    "                     annotation_files=['celegans.bw'],\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on a full chromosomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the method `predict` to predict the nucleosome density on full chromosomes, this prediction can be exported as bigwig files (if a path is passed as argument). One needs to pass a file with chromosome size in two columns tab separated to the method, its name should end with .chrom.sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-23 17:00:55--  https://hgdownload.soe.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.chrom.sizes\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 229 [text/plain]\n",
      "Sauvegarde en : « sacCer3.chrom.sizes »\n",
      "\n",
      "sacCer3.chrom.sizes 100%[===================>]     229  --.-KB/s    ds 0s      \n",
      "\n",
      "2020-11-23 17:00:56 (6.80 MB/s) — « sacCer3.chrom.sizes » sauvegardé [229/229]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/sacCer3/bigZips/sacCer3.chrom.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36926/36926 [==============================] - 1010s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrIX', 'chrX'],\n",
    "                          chrom_size='sacCer3.chrom.sizes',\n",
    "                          export_to_path='prediction_chrIX_chrX.bw',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict on a different genome for example C.elegans with the model trained on S.cerevisiae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-01 14:42:28--  https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.chrom.sizes\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 99 [text/plain]\n",
      "Sauvegarde en : « ce11.chrom.sizes »\n",
      "\n",
      "ce11.chrom.sizes    100%[===================>]      99  --.-KB/s    ds 0s      \n",
      "\n",
      "2020-05-01 14:42:29 (3.42 MB/s) — « ce11.chrom.sizes » sauvegardé [99/99]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/ce11/bigZips/ce11.chrom.sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict and export the prediction in a cross-species context. One just needs to pass the genome of the new species in a fasta file as well as the adapted chromosome sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 10s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrM'],\n",
    "                          chrom_size='ce11.chrom.sizes',\n",
    "                          fasta_file='ce11.fa',\n",
    "                          export_to_path='prediction_celegans.bw',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can predict the nucleosome density with the reversed complemented DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrM'], chrom_size='sacCer3.chrom.sizes', rc=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on a region of chromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` method also make it possible to predict the nucleosome density on a small region of chromosome 9 and on a small region of chromosome 10 for example. One need to pass a list of (start, stop) tuple, in this  example we will predict the nucleosome density between 10000 bp and 20000 bp on chromosome 9 and between 20000 bp and 30000 bp on chromosome 10. Again we can export those prediction on a bigwig file (that will mostly be zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrIX', 'chrX'],\n",
    "                          chrom_size='sacCer3.chrom.sizes',\n",
    "                          start_stop=[(10000, 20000), (20000, 30000)],\n",
    "                          export_to_path='prediction_on_regions.bw',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with multiple inputs / outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with another tracks as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this functionnality we will train a model that takes DNA windows of 2001 bp as inputs as well as the nucleosome density of the 100 centers nucleotides coming from one experiment and predict the the same nucleosome density for another experiment. It is somehow an experiment translators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a multi input model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_extractor = keras.models.Sequential()\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(2001, 4)))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Flatten())\n",
    "\n",
    "dna_inputs = keras.layers.Input(shape=(2001, 4))\n",
    "seq_inputs = keras.layers.Input(shape=(100,))\n",
    "\n",
    "dna_features = dna_extractor(dna_inputs)\n",
    "concatenate = keras.layers.Concatenate()([dna_features, seq_inputs])\n",
    "outputs = keras.layers.Dense(100)(concatenate)\n",
    "\n",
    "model = keras.models.Model([dna_inputs, seq_inputs], outputs)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the corresponding `Generator` instance in order to feed the model with training data. Note that we use a serie of keyword begining by sec to control the secondary input and the keyword tg_window to specify that we want to predict the nucleosome density on a 100 bp window at the center of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw'],\n",
    "                            window=2001,\n",
    "                            tg_window=100,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 100),\n",
    "                            sec_inputs=['scerevisiae2.bw'],\n",
    "                            sec_input_length=100,\n",
    "                            sec_input_shape=(64, 100),\n",
    "                            sec_normalization_mode=['max', 'perctrim'],\n",
    "                            use_sec_as='inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the class method `predict_sec_input_shape` to anticipate the effect of those keyword on the shape of the secondary input. Especially look at the keyword:\n",
    "\n",
    "- number of files passed through sec_inputs\n",
    "- sec_input_length\n",
    "- sec_nb_annotation\n",
    "- sec_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator.predict_sec_input_shape(batch_size=64,\n",
    "                                  fasta_file='sacCer3.fa',\n",
    "                                  annotation_files=['scerevisiae.bw'],\n",
    "                                  window=2001,\n",
    "                                  tg_window=100,\n",
    "                                  normalization_mode=['max', 'perctrim'],\n",
    "                                  incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                                  output_shape=(64, 100),\n",
    "                                  sec_inputs=['scerevisiae2.bw', 'scerevisiae2.bw'],\n",
    "                                  sec_input_length=100,\n",
    "                                  sec_nb_annotation=1,\n",
    "                                  sec_input_shape=None,\n",
    "                                  sec_normalization_mode=['max', 'perctrim'],\n",
    "                                  use_sec_as='inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create as usual the `ModelWrapper` instance, train and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.0085 - val_loss: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feca470cf98>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=5,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 6s 89ms/step - loss: 0.0099 - metric: 0.9362 1s - los\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': 0.9361512}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting two tracks at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw previously, the nucleosome density can change from one experiment to another. We may want to predict several experimental densities at the same time. \n",
    "\n",
    "Here we create a model to predict the nucleosome density at the 100 center nucleotides of every 2001 bp DNA window for two experimental densities at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_track1 = keras.layers.Dense(100)(dna_features)\n",
    "output_track1 = keras.layers.Reshape((100, 1))(output_track1)\n",
    "\n",
    "output_track2 = keras.layers.Dense(100)(dna_features)\n",
    "output_track2 = keras.layers.Reshape((100, 1))(output_track2)\n",
    "\n",
    "output = keras.layers.Concatenate(axis=2, name='output')([output_track1, output_track2])\n",
    "model = keras.models.Model(dna_inputs, output)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass two bigwig files to the keyword annotation_files, one per output of the model. The output shape is also adapted to our need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw', 'scerevisiae2.bw'],\n",
    "                            window=2001,\n",
    "                            tg_window=100,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'],\n",
    "                            output_shape=(64, 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we create a `ModelWrapper` instance, train and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0458 - val_loss: 0.0344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13e8416828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=1,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_correlation` will display the correlation between every predicted density and its corresponding experimental one. As a contrary `evaluate` calculate the mean evaluation on all tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 7s 100ms/step - loss: 0.1910 - correlate_0_0: 0.0031 - correlate_1_0: 2.8998e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': 0.003099391, 'correlate_1_0': 0.00028997537}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `predict` will in this case export one bigwig file for every prediction made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 5s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrIX'],\n",
    "                          export_to_path='prediction_multi_training.bw',\n",
    "                          chrom_size='sacCer3.chrom.sizes',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting simultaneously two tracks for two annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use a model to predict simultaneously two tracks per annotation for two annotations. For example we will download two new nucleosome tracks and suppose that they are single while the two previous were paired-end. We design a CNN that takes 2001 bp long input sequence one-hot-encoded and that predict the nucleosome density at the center nucleotides for the four annotation, the output shape is (batch_size, 1, 2, 2) to separate single-end from paired-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-23 10:06:24--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0030101/Saccharomyces_cerevisiae.scNuc0030101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 2736721 (2.6M) [text/plain]\n",
      "Sauvegarde en : « Saccharomyces_cerevisiae.scNuc0030101.nucleosome.shift.bw »\n",
      "\n",
      "Saccharomyces_cerev 100%[===================>]   2.61M   822KB/s    ds 3.3s    \n",
      "\n",
      "2020-07-23 10:06:27 (822 KB/s) — « Saccharomyces_cerevisiae.scNuc0030101.nucleosome.shift.bw » sauvegardé [2736721/2736721]\n",
      "\n",
      "--2020-07-23 10:06:28--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0040101/Saccharomyces_cerevisiae.scNuc0040101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 2507589 (2.4M) [text/plain]\n",
      "Sauvegarde en : « Saccharomyces_cerevisiae.scNuc0040101.nucleosome.shift.bw »\n",
      "\n",
      "Saccharomyces_cerev 100%[===================>]   2.39M  1.12MB/s    ds 2.1s    \n",
      "\n",
      "2020-07-23 10:06:30 (1.12 MB/s) — « Saccharomyces_cerevisiae.scNuc0040101.nucleosome.shift.bw » sauvegardé [2507589/2507589]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0030101/Saccharomyces_cerevisiae.scNuc0030101.nucleosome.shift.bw\n",
    "!mv Saccharomyces_cerevisiae.scNuc0030101.nucleosome.shift.bw scerevisiae_single1.bw\n",
    "\n",
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Saccharomyces_cerevisiae/bySample/scNuc0040101/Saccharomyces_cerevisiae.scNuc0040101.nucleosome.shift.bw\n",
    "!mv Saccharomyces_cerevisiae.scNuc0040101.nucleosome.shift.bw scerevisiae_single2.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_track1 = keras.layers.Dense(2)(dna_features)\n",
    "output_track1 = keras.layers.Reshape((1, 2, 1))(output_track1)\n",
    "\n",
    "output_track2 = keras.layers.Dense(2)(dna_features)\n",
    "output_track2 = keras.layers.Reshape((1, 2, 1))(output_track2)\n",
    "\n",
    "output = keras.layers.Concatenate(axis=3, name='output')([output_track1, output_track2])\n",
    "model = keras.models.Model(dna_inputs, output)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the `Generator` instance that match our need. We will use the class method `predict_label_shape` to adapt the output shape to our need.\n",
    "\n",
    "Note that the disposition of annotation files given in the list is essential, it should respect the following schema: file1_ann1, file1_ann2, file2_ann1, file2_ann2, in our case file represent the experimental strategy and ann the different example per strategie. In general, one should think at file representing the cellular type and ann a given annotation on this cellular type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator.predict_label_shape(batch_size=64,\n",
    "                              fasta_file='sacCer3.fa',\n",
    "                              annotation_files=['scerevisiae.bw', 'scerevisiae2.bw', 'scerevisiae_single1.bw', 'scerevisiae_single2.bw'],\n",
    "                              nb_annotation_type=2,\n",
    "                              window=2001,\n",
    "                              tg_window=1,\n",
    "                              normalization_mode=['max', 'perctrim'],\n",
    "                              incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/invites/routhier/Documents/keras_dna/keras_dna/extractors.py:85: UserWarning: the list must be organised as [file1_ann1, file1_ann2,\n",
      "            file2_ann1, file2_ann2], with file1, file2 designing two differents kind\n",
      "            of files (different lab, different cellular type ...)\n",
      "  of files (different lab, different cellular type ...)\"\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='sacCer3.fa',\n",
    "                            annotation_files=['scerevisiae.bw', 'scerevisiae2.bw', 'scerevisiae_single1.bw', 'scerevisiae_single2.bw'],\n",
    "                            nb_annotation_type=2,\n",
    "                            window=2001,\n",
    "                            tg_window=1,\n",
    "                            normalization_mode=['max', 'perctrim'],\n",
    "                            incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'])\n",
    "generator_train.label_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a model and a `Generator` the process is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 526s 1s/step - loss: 0.0480 - val_loss: 0.0345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5d0095710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=1,\n",
    "           steps_per_epoch=500,\n",
    "           validation_steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `get_correlation` will display the correlation for every track in the data with the following nomenclatura: correlation_(i - 1)_(j - 1) stand for file(i)_ann(j). In our case the correlation between prediction and screvisiae1.bw will be called correlation_0_0, between prediction and screvisiae2.bw correlation_0_1, scervisiae_single1.bw correlation_1_0 and scervisiae_single2.bw correlation_1_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrIX'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict in this case will output four bigwig file as export_to_path is not None. Their naming will respect the same principle as the result of `get_correlation`: prediction_multi_training_cell_number0_annotation_number0.bw will contain the prediciton corresponding to scerevisiae1.bw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 26s 164ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chrIX'],\n",
    "                          start_stop=[(10000, 15000)],\n",
    "                          export_to_path='prediction_multi_training',\n",
    "                          chrom_size='sacCer3.chrom.sizes',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on several species simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras_dna` makes it easy to use model in a cross species context. As an example suppose we want to predict the nucleosome density on both $\\textit{S.cerevisiae}$ and $\\textit{C.elegans}$ at the same time.\n",
    "\n",
    "To do so we will use two new classes `SeqIntervalDl` and `MultiGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna import SeqIntervalDl, MultiGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes a DNA window of 2001 bp as input and predict the nucleosome density on the 100 centers nucleotides of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(2001, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='linear'))\n",
    "          \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the `MultiGenerator` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of creating a `MultiGeneraor` is not as straighforward as for a `Generator`.\n",
    "\n",
    "One needs first to create a dataset (`SeqIntervalDl` instance) for every species, the keyword are the same as with a `Generator` except batch_size and output_shape that will be passed to the `MultiGenerator`.\n",
    "\n",
    "The `MultiGenerator` is created by passing it the list of dataset. In our example we also pass the number of exemples that we want our generator to yield from every species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_saccer = SeqIntervalDl(fasta_file='sacCer3.fa',\n",
    "                               annotation_files='scerevisiae.bw',\n",
    "                               normalization_mode=['max', 'perctrim'],\n",
    "                               window=2001,\n",
    "                               tg_window=100,\n",
    "                               rc=True,\n",
    "                               incl_chromosomes=['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI'])\n",
    "\n",
    "dataset_celegand = SeqIntervalDl(fasta_file='ce11.fa',\n",
    "                                 annotation_files='celegans.bw',\n",
    "                                 normalization_mode=['max', 'perctrim'],\n",
    "                                 window=2001,\n",
    "                                 tg_window=100,\n",
    "                                 incl_chromosomes=['chrI', 'chrII'])\n",
    "\n",
    "generator_train = MultiGenerator(batch_size=64,\n",
    "                                 dataset_list=[dataset_saccer, dataset_celegand],\n",
    "                                 inst_per_dataset=[64*500, 64*500],\n",
    "                                 output_shape=(64, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same procedure apply for the creation of the validation generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_saccer_val = SeqIntervalDl(fasta_file='sacCer3.fa',\n",
    "                                   annotation_files='scerevisiae.bw',\n",
    "                                   normalization_mode=['max', 'perctrim'],\n",
    "                                   window=2001,\n",
    "                                   tg_window=100,\n",
    "                                   incl_chromosomes=['chrVII', 'chrVIII'])\n",
    "\n",
    "dataset_celegand_val = SeqIntervalDl(fasta_file='ce11.fa',\n",
    "                                     annotation_files='celegans.bw',\n",
    "                                     normalization_mode=['max', 'perctrim'],\n",
    "                                     window=2001,\n",
    "                                     tg_window=100,\n",
    "                                     incl_chromosomes=['chrIII'])\n",
    "\n",
    "generator_val = MultiGenerator(batch_size=64,\n",
    "                               dataset_list=[dataset_saccer_val, dataset_celegand_val],\n",
    "                               inst_per_dataset=[64*200, 64*200],\n",
    "                               output_shape=(64, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `SeqIntervalDl` class owns also the method `predict_input_shape`, `predict_label_shape` and `predict_sec_input_shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeqIntervalDl.predict_label_shape(fasta_file='sacCer3.fa',\n",
    "                                  annotation_files='scerevisiae.bw',\n",
    "                                  normalization_mode=['max', 'perctrim'],\n",
    "                                  window=2001,\n",
    "                                  tg_window=100,\n",
    "                                  incl_chromosomes=['chrVII', 'chrVIII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    generator_val=generator_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally if we want to evaluate our generator we need to specify the species.\n",
    "\n",
    "The method `evaluate` requires that we create a `Generator` instance to yield the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_test = Generator(batch_size=64,\n",
    "                           fasta_file='sacCer3.fa',\n",
    "                           annotation_files='scerevisiae.bw',\n",
    "                           normalization_mode=['max', 'perctrim'],\n",
    "                           window=2001,\n",
    "                           tg_window=100,\n",
    "                           incl_chromosomes=['chrM'],\n",
    "                           output_shape=(64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(generator_eval=generator_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `get_correlation` requires to pass the genome we want to predict on and the nucleosome density we want to compare with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 9s 75ms/step - loss: 0.1759 - metric: -0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correlate_0_0': -0.0020717818}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_correlation(incl_chromosomes=['chrX'],\n",
    "                     fasta_file='sacCer3.fa',\n",
    "                     annotation_files=['scerevisiae.bw'],\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `predict` requires to pass the genome we want to predict on as well as the corresponding chromosome sizes file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 7s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01883128, -0.04754147, -0.0131825 , ...,  0.13192448,\n",
       "        -0.04590571, -0.0558481 ],\n",
       "       [-0.02511727,  0.1061755 , -0.02488164, ...,  0.10167224,\n",
       "         0.0442229 , -0.15225634],\n",
       "       [-0.09656224, -0.05785175,  0.01321044, ...,  0.13336149,\n",
       "         0.09787058, -0.0496234 ],\n",
       "       ...,\n",
       "       [-0.12513319,  0.13154107, -0.11106987, ...,  0.09564744,\n",
       "         0.03229365, -0.08686507],\n",
       "       [-0.05958488,  0.01612343, -0.07622039, ...,  0.18101265,\n",
       "        -0.0049902 , -0.08667748],\n",
       "       [-0.07636375,  0.03420825, -0.01399545, ...,  0.129873  ,\n",
       "         0.05479156, -0.03051661]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.predict(incl_chromosomes=['chrX'],\n",
    "             chrom_size='sacCer3.chrom.sizes',\n",
    "             fasta_file='sacCer3.fa',\n",
    "             export_to_path='multi_prediction.bw',\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will classify DNA sequence between being a binding site for a transcription factor from being background. We will use binding site of a proteins called TAF15 in human genome. The binding sites are defined as peaks of Chip-Seq data.\n",
    "\n",
    "First, we will download the data, then create a convolutional classifier and finally create a `Generator` instance adapted to our model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-19 16:02:56--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 983659424 (938M) [application/x-gzip]\n",
      "Sauvegarde en : « hg38.fa.gz »\n",
      "\n",
      "hg38.fa.gz          100%[===================>] 938.09M  20.3MB/s    ds 55s     \n",
      "\n",
      "2020-11-19 16:03:52 (17.1 MB/s) — « hg38.fa.gz » sauvegardé [983659424/983659424]\n",
      "\n",
      "--2020-11-19 16:04:40--  https://ftp.ncbi.nlm.nih.gov/geo/series/GSE105nnn/GSE105202/suppl/GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz\n",
      "Résolution de ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)… 130.14.250.12, 2607:f220:41e:250::10, 2607:f220:41e:250::11, ...\n",
      "Connexion à ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.12|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 6235743 (5.9M) [application/x-gzip]\n",
      "Sauvegarde en : « GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz »\n",
      "\n",
      "GSE105202_ENCFF979T 100%[===================>]   5.95M  6.44MB/s    ds 0.9s    \n",
      "\n",
      "2020-11-19 16:04:42 (6.44 MB/s) — « GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz » sauvegardé [6235743/6235743]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
    "!gunzip hg38.fa.gz\n",
    "\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE105nnn/GSE105202/suppl/GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz\n",
    "!gunzip GSE105202_ENCFF979TPQ_peaks_GRCh38.bed.gz\n",
    "!mv GSE105202_ENCFF979TPQ_peaks_GRCh38.bed taf15.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study the bed file, we will look at:\n",
    "\n",
    "- the number of peaks\n",
    "- the distribution of length\n",
    "- the distribution between chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2</td>\n",
       "      <td>195656836</td>\n",
       "      <td>195657387</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>366.644608</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2</td>\n",
       "      <td>148645132</td>\n",
       "      <td>148645562</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>323.084459</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr7</td>\n",
       "      <td>35800963</td>\n",
       "      <td>35801305</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>289.978500</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr10</td>\n",
       "      <td>95656633</td>\n",
       "      <td>95656950</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>269.324547</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr7</td>\n",
       "      <td>26200724</td>\n",
       "      <td>26201117</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>258.250077</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.198382</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom      start       stop  0  1  2           3  4         5    6\n",
       "0   chr2  195656836  195657387  .  0  .  366.644608 -1  3.198382  312\n",
       "1   chr2  148645132  148645562  .  0  .  323.084459 -1  3.198382  260\n",
       "2   chr7   35800963   35801305  .  0  .  289.978500 -1  3.198382  185\n",
       "3  chr10   95656633   95656950  .  0  .  269.324547 -1  3.198382  158\n",
       "4   chr7   26200724   26201117  .  0  .  258.250077 -1  3.198382  148"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bedfile = pd.read_csv('taf15.bed', sep='\\t', names=['chrom', 'start', 'stop', '0', '1', '2', '3', '4', '5', '6'])\n",
    "bedfile.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bedfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4657e4a475cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of peaks: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbedfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bedfile' is not defined"
     ]
    }
   ],
   "source": [
    "print('number of peaks: {}'.format(len(bedfile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551, 120, 404.0, 2.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedfile['length'] = bedfile.stop.values - bedfile.start.values\n",
    "bedfile.length.max(), bedfile.length.min(), round(bedfile.length.mean()), round(bedfile.length.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390.0, 410.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = bedfile.length.hist(bins=100)\n",
    "ax.set_xlim(390, 410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299961"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bedfile[bedfile.length == 404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of peaks are of 404 bp long, the maximal length being 551 bp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of peaks on chromosome 1: 33264\n",
      "number of peaks on chromosome 2: 23056\n",
      "number of peaks on chromosome 3: 16904\n",
      "number of peaks on chromosome 4: 16387\n",
      "number of peaks on chromosome 5: 18490\n",
      "number of peaks on chromosome 6: 21000\n",
      "number of peaks on chromosome 7: 22871\n",
      "number of peaks on chromosome 8: 13834\n",
      "number of peaks on chromosome 9: 10067\n",
      "number of peaks on chromosome 10: 13201\n",
      "number of peaks on chromosome 11: 15203\n",
      "number of peaks on chromosome 12: 12347\n",
      "number of peaks on chromosome 13: 4693\n",
      "number of peaks on chromosome 14: 5367\n",
      "number of peaks on chromosome 15: 8144\n",
      "number of peaks on chromosome 16: 11585\n",
      "number of peaks on chromosome 17: 11829\n",
      "number of peaks on chromosome 18: 6147\n",
      "number of peaks on chromosome 19: 12005\n",
      "number of peaks on chromosome 20: 6855\n",
      "number of peaks on chromosome 21: 5179\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 22):\n",
    "    print('number of peaks on chromosome {}: {}'.format(i, len(bedfile[bedfile.chrom == 'chr' + str(i)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a 1D convolutional classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes one-hot-encoded DNA window of 551 bp long as input and classify them between being a binding site or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(551, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the generator to train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fed with a `Generator` instance. The DNA sequence is passed through the fasta file, the positions of binding site are passed through the bed file, we need to precise the batch size and finally that we are predicting binding site.\n",
    "\n",
    "In this exemple, we will train the network on the first five chromosomes, we precise:\n",
    "- the output shape as it is not standard, keyword output_shape\n",
    "- the length of input DNA window, keyword seq_len\n",
    "- the negative ratio to its default value of 1, keyword negative_ratio\n",
    "\n",
    "Note that the length of the input can be set to the maximal length encounter by specifying seq_len='MAXLEN' (default behaviour), but it will be the maximal length in the 5 first chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq_len=551,\n",
    "                            negative_ratio=1,\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `ModelWrapper` instance to associate the model to its `Generator` instance, train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/invites/routhier/Documents/keras_dna/keras_dna/model.py:131: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/3\n",
      "3378/3378 [==============================] - 224s 66ms/step - loss: 0.5986 - accuracy: 0.6543 - val_loss: 0.5912 - val_accuracy: 0.6691\n",
      "Epoch 2/3\n",
      "3378/3378 [==============================] - 211s 62ms/step - loss: 0.5847 - accuracy: 0.6690 - val_loss: 0.6050 - val_accuracy: 0.6459\n",
      "Epoch 3/3\n",
      "3378/3378 [==============================] - 211s 62ms/step - loss: 0.5756 - accuracy: 0.6755 - val_loss: 0.5861 - val_accuracy: 0.6706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c1979c9e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 20s 47ms/step - loss: 0.5892 - accuracy: 0.6690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5891944118258026, 0.6689815]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chr8'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the acuracy of our binding site detector at a chromosome scale, we calculate the AUROC on all the available data on a chromosome. We can choose to either consider one positive example per binding site or to apply data augmentation (all the window containing a whole binding site will be considered as positive example). Negative examples are every windows whitout having any intersection with positive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_auc(incl_chromosomes=['chr8'], data_augmentation=False, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This evaluation can be made on another species if we pass the DNA sequence through a fasta file, and the annotation file. As an example we use the human genome as if it was a new species. We will calculate the area under Precision-Recall curve in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 25s 57ms/step - loss: 0.6990 - auc_3: 0.4918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cell_idx': 0, 'annotation': 'binding site', 'AUPR': 0.49177095}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.get_auc(incl_chromosomes=['chr8'],\n",
    "             fasta_file='hg38.fa',\n",
    "             data_augmentation=False,\n",
    "             annotation_files=['taf15.bed'],\n",
    "             curve='PR',\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our detector in hand we can predict the presence of binding site along a chromosome. To do so we use the method `predict`. As we saw in the regression section we need to pass the chromosome size as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-08 11:12:22--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes\n",
      "Résolution de hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)… 128.114.119.163\n",
      "Connexion à hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 11672 (11K) [text/plain]\n",
      "Sauvegarde en : « hg38.chrom.sizes »\n",
      "\n",
      "hg38.chrom.sizes    100%[===================>]  11.40K  --.-KB/s    ds 0s      \n",
      "\n",
      "2020-05-08 11:12:23 (117 MB/s) — « hg38.chrom.sizes » sauvegardé [11672/11672]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 3s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = wrap.predict(incl_chromosomes=['chr8'],\n",
    "                          chrom_size='hg38.chrom.sizes',\n",
    "                          export_to_path='taf15_prediction.bw',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with random negative example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train our model with random sequence as negative exemple, it may be useful as a first easy training before reusing the network to train it with the real problem.\n",
    "\n",
    "One need to specify ```negative_type = 'random'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq_len=551,\n",
    "                            negative_ratio=1,\n",
    "                            negative_type='random',\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                   generator_train=generator_train,\n",
    "                   validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3378/3378 [==============================] - 280s 83ms/step - loss: 0.0268 - accuracy: 0.9888 - val_loss: 0.0036 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56c8b4be80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background sequences are far more numerous than binding site. To mitigate this fact one can apply a data-augmentation procedure. Here, we will use an input window of 414 bp (10 bp more than the majority of positive sequence) and apply data-augmentation. All the sequences of length 414 bp containing a binding site will be considered as positive exemples (it multiplies roughly the number of positives examples by 10), longer sequences will be cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(414, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq_len=414,\n",
    "                            negative_ratio=1,\n",
    "                            data_augmentation=True,\n",
    "                            output_shape=(64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chr8'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisely predict the position of binding site whitin a sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to set precisely the position of binding site within sequences that contain one. To do so we will train a seq2seq model and limit the training data to positive examples. We will apply a data augmentation strategy to gain more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes input of 416 bp long and return an output of the same size with 1 where the binding sites are and 0 elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(16, (3, 1), activation='relu', padding='same', input_shape=(416, 4, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 1), padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (10, 1), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 1), padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (20, 1), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 1), padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2DTranspose(64, (20, 1), strides=(2, 1), activation='relu', padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2DTranspose(32, (10, 1), strides=(2, 1), activation='relu', padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2DTranspose(16, (3, 1), strides=(2, 1), activation='relu', padding='same'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(1, (1, 4), activation='sigmoid', padding='valid'))\n",
    "model.add(keras.layers.Reshape((416, 1)))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an adapted `Generator` instance. First notice that we set seq2seq to True to specify that we will train a seq2seq model. The negative example are discarted by setting negative_type to None. As the model is now a 2D convolutional network we add a final dummy axis to the input (dummy_axis=2). The standard output shape is (batch_size, output_length, # cellular type, # annotation to predict at the same time), here (64, 416, 1, 1), we remove one dummy axis by specifying output_shape=(64, 416, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                            seq2seq=True,\n",
    "                            data_augmentation=True,\n",
    "                            defined_positive='match_any',\n",
    "                            seq_len=416,\n",
    "                            dummy_axis=2,\n",
    "                            negative_type=None,\n",
    "                            output_shape=(64, 416, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train,\n",
    "                    validation_chr=['chr6', 'chr7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.evaluate(incl_chromosomes=['chr8'], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label shape and functionnalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we different classification problem and how one can the create corresponding  `Generator` instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Predicting the same annotation on different cellular type:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine the ChIP-seq peak data in two different cell types and we want to classify if a sequence is a peak of ChIP-seq in both callular type. We will just copy our data to use it as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp taf15.bed taf15_heart.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator.predict_label_shape(batch_size=64,\n",
    "                              fasta_file='hg38.fa',\n",
    "                              annotation_files=['taf15.bed', 'taf15_heart.bed'],\n",
    "                              annotation_list=['binding site'],\n",
    "                              incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                              seq2seq=False,\n",
    "                              data_augmentation=False,\n",
    "                              defined_positive='match_any',\n",
    "                              seq_len=404,\n",
    "                              negative_type=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard output shape is (2, 1) corresponding to (nb_cellular_type, nb_annotation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Positioning precisely ChIP-seq peaks in two cellular type:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we want to precisely set where the peaks are in both cell type. Let's change seq_len and turn seq2seq to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 2, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator.predict_label_shape(batch_size=64,\n",
    "                              fasta_file='hg38.fa',\n",
    "                              annotation_files=['taf15.bed', 'taf15_heart.bed'],\n",
    "                              annotation_list=['binding site'],\n",
    "                              incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                              seq2seq=True,\n",
    "                              data_augmentation=False,\n",
    "                              defined_positive='match_any',\n",
    "                              seq_len=420,\n",
    "                              negative_type=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard output shape correspond to (length_of_input, nb_cellular_type, nb_annotation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Predicting several annotation at the same time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will classify here sequences as begining of a gene, begining of a pseudogene or background. Note that the gff file is the format adapted to this task as a bed file contains only one kind of annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-23 15:10:24--  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.gff.gz\n",
      "           => « GCF_000001405.39_GRCh38.p13_genomic.gff.gz »\n",
      "Résolution de ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)… 130.14.250.11, 2607:f220:41e:250::11, 2607:f220:41e:250::12, ...\n",
      "Connexion à ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.11|:21… connecté.\n",
      "Ouverture de session en tant que anonymous… Session établie.\n",
      "==> SYST ... terminé.    ==> PWD ... terminé.\n",
      "==> TYPE I ... terminé.  ==> CWD (1) /genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13 ... terminé.\n",
      "==> SIZE GCF_000001405.39_GRCh38.p13_genomic.gff.gz ... 49043324\n",
      "==> PASV ... terminé.    ==> RETR GCF_000001405.39_GRCh38.p13_genomic.gff.gz ... terminé.\n",
      "Taille : 49043324 (47M) (non certifiée)\n",
      "\n",
      "GCF_000001405.39_GR 100%[===================>]  46.77M  13.8MB/s    ds 3.9s    \n",
      "\n",
      "2020-07-23 15:10:29 (12.1 MB/s) - « GCF_000001405.39_GRCh38.p13_genomic.gff.gz » sauvegardé [49043324]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.gff.gz\n",
    "! gunzip GCF_000001405.39_GRCh38.p13_genomic.gff.gz\n",
    "\n",
    "### Replace the NCBI chromosome name by a simpler\n",
    "! perl -pe 's/NC_000001.11/chr1/g' GCF_000001405.39_GRCh38.p13_genomic.gff > hg38_gene.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Generator` instance that yield the DNA sequence around the start of an annotation example, set predict='start'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator.predict_label_shape(batch_size=64,\n",
    "                              fasta_file='hg38.fa',\n",
    "                              annotation_files=['hg38_gene.gff'],\n",
    "                              annotation_list=['gene', 'pseudogene'],\n",
    "                              incl_chromosomes=['chr1'],\n",
    "                              seq2seq=False,\n",
    "                              data_augmentation=False,\n",
    "                              seq_len=299,\n",
    "                              predict='start')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the standard format is (number of cell type = number of gff file passed, number of annotation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and regression simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use a CNN network to predict both if a sequence is binding site and the nucleosome coverage on the sequence.\n",
    "\n",
    "First, let's download a bigwig file containing the nucleosome coverage on the human genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-23 16:02:02--  http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Homo_sapiens/bySample/hsNuc0010101/Homo_sapiens.hsNuc0010101.nucleosome.shift.bw\n",
      "Résolution de bigd.big.ac.cn (bigd.big.ac.cn)… 124.16.129.109\n",
      "Connexion à bigd.big.ac.cn (bigd.big.ac.cn)|124.16.129.109|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 349021252 (333M) [text/plain]\n",
      "Sauvegarde en : « Homo_sapiens.hsNuc0010101.nucleosome.shift.bw »\n",
      "\n",
      "Homo_sapiens.hsNuc0 100%[===================>] 332.85M  4.31MB/s    ds 2m 39s  \n",
      "\n",
      "2020-07-23 16:04:42 (2.09 MB/s) — « Homo_sapiens.hsNuc0010101.nucleosome.shift.bw » sauvegardé [349021252/349021252]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://bigd.big.ac.cn/nucmap/NucMap_FTP_Directory/Homo_sapiens/bySample/hsNuc0010101/Homo_sapiens.hsNuc0010101.nucleosome.shift.bw\n",
    "!mv Homo_sapiens.hsNuc0010101.nucleosome.shift.bw homo_sapiens.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a CNN that takes the DNA sequence one-hot-encoded as input and returns a classification between being a binding site and the nucleosome density covering the DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_extractor = keras.models.Sequential()\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(404, 4)))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "dna_extractor.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "dna_extractor.add(keras.layers.Flatten())\n",
    "\n",
    "dna_inputs = keras.layers.Input(shape=(404, 4))\n",
    "\n",
    "dna_features = dna_extractor(dna_inputs)\n",
    "\n",
    "output_classifier = keras.layers.Dense(1, activation='sigmoid')(dna_features)\n",
    "output_density = keras.layers.Dense(404, activation='linear')(dna_features)\n",
    "\n",
    "model = keras.models.Model(dna_inputs, [output_classifier, output_density])\n",
    "model.compile(loss=['binary_crossentropy', 'mae'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the sec_input keyword to create a `Generetor` instance that yields two labels at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator(batch_size=64,\n",
    "                            fasta_file='hg38.fa',\n",
    "                            annotation_files=['taf15.bed'],\n",
    "                            annotation_list=['binding site'],\n",
    "                            incl_chromosomes=['chr1'],\n",
    "                            seq_len=404,\n",
    "                            negative_ratio=1,\n",
    "                            negative_type='real',\n",
    "                            output_shape=(64, 1),\n",
    "                            sec_inputs=['homo_sapiens.bw'],\n",
    "                            sec_input_length=404,\n",
    "                            sec_input_shape=(64, 404),\n",
    "                            sec_normalization_mode=['max', 'perctrim'],\n",
    "                            use_sec_as='targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train)\n",
    "\n",
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Genome training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our network we use the hg38 genome in the direct strand. As an exemple of training a network on several genome at the same time we will use hg38 in the direct strand and hg38 in the reverse strand.\n",
    "\n",
    "Note that the procedure is the same if we want to train a network on several genome at the same time (several species, assembly). In particular we use `SeqIntervalDl` and `MultiGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dna import SeqIntervalDl, MultiGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu', input_shape=(551, 4)))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "dna_input\n",
    "model.add(keras.layers.Conv1D(32, 10, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, 20, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare one `SeqIntervalDl` instance in the direct strand and another in the reverse one. They are associated in a `MultiGenerator` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_direct = SeqIntervalDl(fasta_file='hg38.fa',\n",
    "                                annotation_files=['taf15.bed'],\n",
    "                                annotation_list=['binding site'],\n",
    "                                incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                                seq_len=551,\n",
    "                                negative_ratio=1,\n",
    "                                negative_type='real')\n",
    "\n",
    "dataset_reversed = SeqIntervalDl(fasta_file='hg38.fa',\n",
    "                                  annotation_files=['taf15.bed'],\n",
    "                                  annotation_list=['binding site'],\n",
    "                                  incl_chromosomes=['chr1', 'chr2', 'chr3', 'chr4', 'chr5'],\n",
    "                                  seq_len=551,\n",
    "                                  negative_ratio=1,\n",
    "                                  rc=True,\n",
    "                                  negative_type='real')\n",
    "\n",
    "generator_train = MultiGenerator(batch_size=64,\n",
    "                                 dataset_list=[dataset_direct, dataset_reversed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a `ModelWrapper` instance and train it as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = ModelWrapper(model=model,\n",
    "                    generator_train=generator_train)\n",
    "\n",
    "wrap.train(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we want to evaluate the prediction in the direct strand. As we used a `MultiGenerator` instance, we need to precise both the fasta file and the annotation file in the `get_auc` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.get_auc(incl_chromosomes=['chr8'],\n",
    "             data_augmentation=True,\n",
    "             fasta_file='hg38.fa',\n",
    "             annotation_files=['taf15.bed'],\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same apply for prediction, the fasta file need to be precised. Here we set rc to True in order to predict in the reverse strand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.predict(incl_chromosomes=['chr8'],\n",
    "             chrom_size='hg38.chrom.sizes',\n",
    "             fasta_file='hg38.fa',\n",
    "             rc=True,\n",
    "             verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_env]",
   "language": "python",
   "name": "conda-env-test_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
